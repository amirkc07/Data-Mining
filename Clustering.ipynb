{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import cycle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def main(cgm,insulin):\n",
    "    ## Read CGM Data\n",
    "    cgmdata=pd.read_csv(cgm)\n",
    "  \n",
    "    ## Read Insulind data \n",
    "    insulindata=pd.read_csv(insulin)\n",
    "   \n",
    "   \n",
    "    ##Subset CGM\n",
    "    insulin=insulindata[[\"Index\",\"Date\",\"Time\",\"BWZ Carb Input (grams)\"]]\n",
    "    \n",
    "    #Merge date time\n",
    "    insulin['dt']=pd.to_datetime(insulin['Date'] + ' ' + insulin['Time'])\n",
    "    #Rename column\n",
    "    insulin = insulin.rename(columns={'BWZ Carb Input (grams)': 'carbinput'})\n",
    "    #Subset carb input >0\n",
    "    insulin_new=insulin[insulin[\"carbinput\"] >0]\n",
    "    insulin_new['tm2'] = pd.DatetimeIndex(insulin_new['dt'])\n",
    "    #subset columns\n",
    "    insulin_join=insulin_new[[\"dt\",\"carbinput\",\"tm2\"]]\n",
    "    #sort by date time\n",
    "    insulin_sort=insulin_join.sort_values(by='dt')\n",
    "    # Choose start time\n",
    "    insulin_sort['lagtime'] = (insulin_sort['dt'].shift(-1))\n",
    "    insulin_sort['diff']=insulin_sort['lagtime']-insulin_sort['dt']\n",
    "    insulin_sort=insulin_sort[insulin_sort['diff'] >='02:00:00']\n",
    "\n",
    "    ##Read,Subset and sort CGM\n",
    "    cgm=cgmdata[[\"Index\",\"Date\",\"Time\",\"Sensor Glucose (mg/dL)\"]]\n",
    "    cgm['dt']=pd.to_datetime(cgm['Date'] + ' ' + cgm['Time'])\n",
    "    cgm_sort=cgm.sort_values(by='dt')\n",
    "    \n",
    "    #Merge cgm_sort and insulin_sort\n",
    "    new=pd.merge_asof(\n",
    "    cgm_sort,\n",
    "    insulin_sort,\n",
    "   # by=\"component\",\n",
    "    right_on=\"dt\",\n",
    "    left_on=\"dt\",\n",
    "    direction='nearest',\n",
    "    tolerance=pd.Timedelta('2.5 minute'))\n",
    "    \n",
    "    new_fin=new[new[\"carbinput\"]>0]\n",
    "    new_fin['tm']=pd.to_datetime(new_fin['Date'] + ' ' + new_fin['Time'])\n",
    "    new_fin['tm2meal'] = pd.DatetimeIndex(new_fin['tm']) + timedelta(hours=2,minutes=0)\n",
    "    new_fin['tm30meal'] = pd.DatetimeIndex(new_fin['tm']) - timedelta(hours=0,minutes=30)\n",
    "    new_fin['tm2nomeal'] = pd.DatetimeIndex(new_fin['tm2meal']) + timedelta(hours=2,minutes=0)\n",
    "    new_fin=new_fin[[\"dt\",\"tm\",\"tm2meal\",\"tm30meal\",\"tm2nomeal\"]]\n",
    "    \n",
    "    #merge new with meal dates\n",
    "    newfinal=pd.merge_asof(\n",
    "    new,\n",
    "    new_fin,\n",
    "   # by=\"component\",\n",
    "    right_on=\"dt\",\n",
    "    left_on=\"dt\",\n",
    "    direction='nearest',\n",
    "    tolerance=pd.Timedelta('1 minute'))\n",
    "    \n",
    "    ####### MEAL DATA EXTRACTION ##########\n",
    "    newsubset=newfinal[newfinal[\"carbinput\"]>0]\n",
    "    mealtime=newsubset[[\"tm30meal\"]]\n",
    "    mealtime[\"dt\"]=mealtime[\"tm30meal\"]\n",
    "    \n",
    "    newfinal2=pd.merge_asof(\n",
    "    newfinal,\n",
    "    mealtime,\n",
    "   # by=\"component\",\n",
    "    right_on=\"dt\",\n",
    "    left_on=\"dt\",\n",
    "    tolerance=pd.Timedelta('30 minute'))\n",
    "    \n",
    "    mealtime2=newsubset[[\"tm\",\"tm2meal\"]]\n",
    "    mealtime2[\"dt\"]=mealtime2[\"tm\"]\n",
    "    \n",
    "    newfinal3=pd.merge_asof(\n",
    "    newfinal2,\n",
    "    mealtime2,\n",
    "   # by=\"component\",\n",
    "    right_on=\"dt\",\n",
    "    left_on=\"dt\",\n",
    "    tolerance=pd.Timedelta('120 minute'))\n",
    "    \n",
    "    Mergedfinal=newfinal3[(newfinal3[\"tm30meal_y\"].notna()) | (newfinal3[\"tm2meal_y\"].notna())]\n",
    "    mealdata=Mergedfinal[[\"Sensor Glucose (mg/dL)\"]]\n",
    "    mealdata = mealdata.reset_index()\n",
    "    mealdata=mealdata[[\"Sensor Glucose (mg/dL)\"]]\n",
    "    #Imput missing observations with mean value\n",
    "    mealdata['Sensor Glucose (mg/dL)'].fillna(mealdata['Sensor Glucose (mg/dL)'].mean(), inplace = True)\n",
    "    \n",
    "    \n",
    "    seq= cycle([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30])\n",
    "    mealdata['x'] = [next(seq) for count in range(mealdata.shape[0])]\n",
    "    mealdata['y']=0\n",
    "    mealdata['y'] = (mealdata[\"x\"] %30==0).shift(1).cumsum() + 1\n",
    "    mealdata['y'].fillna(value=1, inplace = True)\n",
    "    \n",
    "    meal_data=mealdata.pivot(index='y',columns='x', values='Sensor Glucose (mg/dL)').add_prefix('X').reset_index()\n",
    "    \n",
    "    ####### NO MEAL DATA EXTRACTION ##########\n",
    "    mealtime3=newsubset[[\"tm\",\"tm2nomeal\"]]\n",
    "    mealtime3[\"dt\"]=mealtime3[\"tm2nomeal\"]\n",
    "    \n",
    "    newfinal4=pd.merge_asof(\n",
    "    newfinal2,\n",
    "    mealtime3,\n",
    "   # by=\"component\",\n",
    "    right_on=\"dt\",\n",
    "    left_on=\"dt\",\n",
    "    tolerance=pd.Timedelta('120 minute'))\n",
    "    \n",
    "    Mergedfinal2=newfinal4[(newfinal4[\"tm2nomeal_y\"].notna())]\n",
    "    nomealdata=Mergedfinal2[[\"Sensor Glucose (mg/dL)\"]]\n",
    "    nomealdata = nomealdata.reset_index()\n",
    "    nomealdata=nomealdata[[\"Sensor Glucose (mg/dL)\"]]\n",
    "\n",
    "    #Imput missing observations with mean value\n",
    "    nomealdata['Sensor Glucose (mg/dL)'].fillna(nomealdata['Sensor Glucose (mg/dL)'].mean(), inplace = True)\n",
    "    seq= cycle([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24])\n",
    "    nomealdata['x'] = [next(seq) for count in range(nomealdata.shape[0])]\n",
    "    nomealdata['y']=0\n",
    "    nomealdata['y'] = (nomealdata[\"x\"] %24==0).shift(1).cumsum() + 1\n",
    "    nomealdata['y'].fillna(value=1, inplace = True)\n",
    "    nomeal_data=nomealdata.pivot(index='y',columns='x', values='Sensor Glucose (mg/dL)').add_prefix('X').reset_index()\n",
    "    \n",
    "    \n",
    "    ##Drop x and y\n",
    "    meal_data.drop(['y'], axis=1, inplace=True)\n",
    "    nomeal_data.drop(['y'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "   ##Min max value training\n",
    "    meal_data['max_value'] = meal_data.max(axis=1)\n",
    "    meal_data['min_value'] = meal_data.min(axis=1)\n",
    "    meal_data['std'] = meal_data.std(axis=1)\n",
    "    meal_data['dev']=(meal_data['max_value']-meal_data['min_value'])/(meal_data['min_value'])\n",
    "    \n",
    "    nomeal_data['max_value'] = nomeal_data.max(axis=1)\n",
    "    nomeal_data['min_value'] = nomeal_data.min(axis=1)\n",
    "    nomeal_data['std'] = nomeal_data.std(axis=1)\n",
    "    nomeal_data['dev']=(nomeal_data['max_value']-nomeal_data['min_value'])/(nomeal_data['min_value'])\n",
    "    \n",
    "    ##Set meal & no meal indicator\n",
    "    meal_data['label']=1\n",
    "    nomeal_data['label']=0\n",
    "    \n",
    "    #Subset final features and label\n",
    "    meal=meal_data[[\"std\",\"dev\",\"label\"]]\n",
    "    nomeal=nomeal_data[[\"std\",\"dev\",\"label\"]]\n",
    "    \n",
    "    ###Extract Ground Truth###\n",
    "    min_value=newsubset['carbinput'].min()\n",
    "    max_value=newsubset['carbinput'].max()\n",
    "    ##Total Number of Bins\n",
    "    k=round((max_value-min_value)/20)\n",
    "    \n",
    "    newsubset['groundtruth'] = pd.qcut(newsubset['carbinput'], q=k, labels=[0,1,2,3,4,5])\n",
    "    binmatrix=newsubset[[\"carbinput\",\"groundtruth\"]]\n",
    "    binmatrix=binmatrix.reset_index()\n",
    "    binmatrix.index.name='x'\n",
    "    \n",
    "    ##K-mean \n",
    "    scaled_features=meal.copy()\n",
    "    col_names=['std','dev']\n",
    "    features=meal[col_names]\n",
    "    scaler=StandardScaler().fit(features.values)\n",
    "    features=scaler.transform(features.values)\n",
    "    \n",
    "    scaled_features[col_names]=features\n",
    "    \n",
    "\n",
    "    kmeans=KMeans(init=\"random\",n_clusters=k,n_init=10,max_iter=300,random_state=42)\n",
    "    kmeans.fit(scaled_features)\n",
    "    \n",
    "    P=kmeans.predict(scaled_features)\n",
    "    \n",
    "    scaled_features['predicted'] = pd.Series(P, index=scaled_features.index)\n",
    "    mergedkmean = pd.merge(scaled_features, binmatrix, left_index=True, right_on='groundtruth')\n",
    "    mergedkmean=mergedkmean.sort_index()\n",
    "    \n",
    "    ##K-mean SSE Calculation\n",
    "    ksse=kmeans.inertia_\n",
    "     \n",
    "    #Create confusion matrix \n",
    "    y_test = mergedkmean['groundtruth'].tolist()\n",
    "    y_pred = mergedkmean['predicted'].tolist()\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cmdf = pd.DataFrame(cm)\n",
    "    \n",
    "    #Calculate purity\n",
    "    cmdf2=cmdf.copy()\n",
    "    cmdf.loc[\"TotalC\"] = cmdf.sum()\n",
    "    cmdf.loc[:,'TotalR'] = cmdf.sum(numeric_only=True, axis=1)\n",
    "    rowtotal=cmdf.loc['TotalC','TotalR']\n",
    "    \n",
    "    cmdf2['max_value'] = cmdf2.max(axis=1)\n",
    "    columntotal=cmdf2['max_value'].sum()\n",
    "    \n",
    "    kpurity=round(cmdf2['max_value'].sum()/cmdf.loc['TotalC','TotalR'])\n",
    "    \n",
    "    #Calculate entropy kmean\n",
    "    \n",
    "    ck0=((cmdf.loc[0,4]/cmdf.loc[0,'TotalR'])*np.log(cmdf.loc[0,4]/cmdf.loc[0,'TotalR']))*(cmdf.loc[0,'TotalR']/rowtotal)\n",
    "    ck1=((cmdf.loc[1,3]/cmdf.loc[1,'TotalR'])*np.log(cmdf.loc[1,3]/cmdf.loc[1,'TotalR']))*(cmdf.loc[1,'TotalR']/rowtotal)\n",
    "    ck2=((cmdf.loc[2,0]/cmdf.loc[2,'TotalR'])*np.log(cmdf.loc[2,0]/cmdf.loc[2,'TotalR']))*(cmdf.loc[2,'TotalR']/rowtotal)\n",
    "    ck3=((cmdf.loc[3,5]/cmdf.loc[3,'TotalR'])*np.log(cmdf.loc[3,5]/cmdf.loc[3,'TotalR']))*(cmdf.loc[3,'TotalR']/rowtotal)\n",
    "    ck4=((cmdf.loc[4,3]/cmdf.loc[4,'TotalR'])*np.log(cmdf.loc[4,3]/cmdf.loc[4,'TotalR']))*(cmdf.loc[4,'TotalR']/rowtotal)\n",
    "    ck5=((cmdf.loc[5,4]/cmdf.loc[5,'TotalR'])*np.log(cmdf.loc[5,4]/cmdf.loc[5,'TotalR']))*(cmdf.loc[5,'TotalR']/rowtotal)\n",
    "    \n",
    "    kmentropy=((ck0+ck1+ck2+ck3+ck4+ck5))\n",
    "    \n",
    "    ##DBSCAN Algorithm\n",
    "    db=DBSCAN(eps=0.50,min_samples=3)\n",
    "    db.fit(scaled_features)\n",
    "    \n",
    "    #dbpred=db.predict(scaled_features)\n",
    "    labels = db.labels_\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    \n",
    "    scaled_features['predictdb'] = pd.Series(labels, index=scaled_features.index)\n",
    "    mergeddbscan = pd.merge(scaled_features, binmatrix, left_index=True, right_on='groundtruth')\n",
    "    \n",
    "    #Create confusion matrix \n",
    "    y_test = mergeddbscan['groundtruth'].tolist()\n",
    "    y_pred = mergeddbscan['predictdb'].tolist()\n",
    "    cmdb = confusion_matrix(y_test, y_pred)\n",
    "    cmdb = pd.DataFrame(cmdb)\n",
    "    \n",
    "    #Dbscansse\n",
    "    mse=mean_squared_error(y_test, y_pred)\n",
    "    counts= np.count_nonzero(y_test)\n",
    "    dbsse=mse*counts\n",
    "    \n",
    "    ##Purity\n",
    "    cmdb2=cmdb.copy()\n",
    "    cmdb.loc[\"TotalC\"] = cmdb.sum()\n",
    "    cmdb.loc[:,'TotalR'] = cmdb.sum(numeric_only=True, axis=1)\n",
    "    rowtotal=cmdb.loc['TotalC','TotalR']\n",
    "    \n",
    "    cmdb2['max_value'] = cmdb2.max(axis=1)\n",
    "    columntotal=cmdb2['max_value'].sum()\n",
    "    \n",
    "    dbpurity=round(cmdb2['max_value'].sum()/cmdb.loc['TotalC','TotalR'])\n",
    "    \n",
    "    #Calculate entropy dbscan\n",
    "    \n",
    "    c0=((cmdb.loc[0,0]/cmdb.loc[0,'TotalR'])*np.log(cmdb.loc[0,0]/cmdb.loc[0,'TotalR']))*(cmdb.loc[0,'TotalR']/rowtotal)\n",
    "    c1=((cmdb.loc[1,1]/cmdb.loc[1,'TotalR'])*np.log(cmdb.loc[1,1]/cmdb.loc[1,'TotalR']))*(cmdb.loc[1,'TotalR']/rowtotal)\n",
    "    c2=((cmdb.loc[2,5]/cmdb.loc[2,'TotalR'])*np.log(cmdb.loc[2,5]/cmdb.loc[2,'TotalR']))*(cmdb.loc[2,'TotalR']/rowtotal)\n",
    "    c3=((cmdb.loc[3,2]/cmdb.loc[3,'TotalR'])*np.log(cmdb.loc[3,2]/cmdb.loc[3,'TotalR']))*(cmdb.loc[3,'TotalR']/rowtotal)\n",
    "    c4=((cmdb.loc[4,1]/cmdb.loc[4,'TotalR'])*np.log(cmdb.loc[4,1]/cmdb.loc[4,'TotalR']))*(cmdb.loc[4,'TotalR']/rowtotal)\n",
    "    c5=((cmdb.loc[5,0]/cmdb.loc[5,'TotalR'])*np.log(cmdb.loc[5,0]/cmdb.loc[5,'TotalR']))*(cmdb.loc[5,'TotalR']/rowtotal)\n",
    "    \n",
    "    dbentropy=((c0+c1+c2+c3+c4+c5))\n",
    "    \n",
    "    data={'kmsse':[ksse],'dbsse':[dbsse],'kent':[kmentropy],'dbent':[dbentropy],'kmpure':[kpurity],'dbpure':[dbpurity]}\n",
    "\n",
    "    finalresult = pd.DataFrame (data, columns = ['kmsse','dbsse','kent','dbent','kmpure','dbpure'])\n",
    "    \n",
    "    return(finalresult.to_csv('Result.csv',header=False, index=False))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Akc/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2909: DtypeWarning: Columns (32) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "/Users/Akc/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2909: DtypeWarning: Columns (13,43) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "/Users/Akc/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Akc/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Akc/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Akc/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Akc/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Akc/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Akc/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Akc/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Akc/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Akc/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:114: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Akc/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:169: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.175787728026534"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main('Desktop/Project2/CGMData.csv','Desktop/Project2/InsulinData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
